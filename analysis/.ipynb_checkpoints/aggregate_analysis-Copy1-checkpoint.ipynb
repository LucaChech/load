{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from pdb import set_trace\n",
    "import pdb\n",
    "#%pdb\n",
    "#mypath = 'E:/OneDrive - University College London/load/pilot_6_data/'\n",
    "#mypath = 'C:/Users/KeK/OneDrive - University College London/load/pilot_6_data/'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from process import *\n",
    "#from test import *\n",
    "from tables import *\n",
    "\n",
    "pd.set_option('display.max_rows', 9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\n",
      "MEAN TO:  1.1834716151\n",
      "TO WINDOW:  0.428892306638 1.93805092356\n",
      "TO rejects n:  1\n",
      "VS rejects N:  3\n",
      "CORRECT VS:  110\n",
      "{'vs_accuracy_diff': 0.2229760289461783, 'tone_detection_accuracy_low': 0.875, 'false_alarms_low': 0, 'tone_detection_accuracy_diff': 0.04166666666666663, 'tone_detection_accuracy_high': 0.8333333333333334, 'false_alarms_high': 0, 'vs_accuracy_high': 0.7164179104477612, 'vs_accuracy_low': 0.9393939393939394}\n"
     ]
    }
   ],
   "source": [
    "f = '../output/participant_7.pik'\n",
    "import pickle\n",
    "with open(f,'r') as of:\n",
    "    D = pickle.load(of)\n",
    "df = pd.DataFrame.from_dict(D['experiment_details'],orient='index')\n",
    "\n",
    "new_df, notes = process(df)\n",
    "print notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "participants = ['1','2','3','4','5','6','7','8','9','10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\n",
      "MEAN TO:  1.47927871794\n",
      "TO WINDOW:  0.453356333156 2.50520110272\n",
      "TO rejects n:  0\n",
      "VS rejects N:  2\n",
      "CORRECT VS:  117\n",
      "960\n",
      "MEAN TO:  1.64327474029\n",
      "TO WINDOW:  0.942279519948 2.34426996063\n",
      "TO rejects n:  0\n",
      "VS rejects N:  6\n",
      "CORRECT VS:  116\n",
      "960\n",
      "MEAN TO:  1.32639641756\n",
      "TO WINDOW:  0.515620599767 2.13717223536\n",
      "TO rejects n:  1\n",
      "VS rejects N:  4\n",
      "CORRECT VS:  109\n",
      "960\n",
      "MEAN TO:  0.888448123494\n",
      "TO WINDOW:  -3.98146126077 5.75835750776\n",
      "TO rejects n:  1\n",
      "VS rejects N:  6\n",
      "CORRECT VS:  118\n",
      "960\n",
      "MEAN TO:  1.24973741412\n",
      "TO WINDOW:  0.370487393209 2.12898743502\n",
      "TO rejects n:  1\n",
      "VS rejects N:  3\n",
      "CORRECT VS:  129\n",
      "960\n",
      "MEAN TO:  nan\n",
      "TO WINDOW:  nan nan\n",
      "TO rejects n:  0\n",
      "VS rejects N:  3\n",
      "CORRECT VS:  109\n",
      "960\n",
      "MEAN TO:  1.1834716151\n",
      "TO WINDOW:  0.428892306638 1.93805092356\n",
      "TO rejects n:  1\n",
      "VS rejects N:  3\n",
      "CORRECT VS:  110\n",
      "960\n",
      "MEAN TO:  0.911045051841\n",
      "TO WINDOW:  -0.18274115407 2.00483125775\n",
      "TO rejects n:  6\n",
      "VS rejects N:  5\n",
      "CORRECT VS:  94\n",
      "960\n",
      "MEAN TO:  1.33964470157\n",
      "TO WINDOW:  0.616400066294 2.06288933686\n",
      "TO rejects n:  0\n",
      "VS rejects N:  6\n",
      "CORRECT VS:  106\n",
      "960\n",
      "MEAN TO:  1.48571804182\n",
      "TO WINDOW:  0.50885806419 2.46257801945\n",
      "TO rejects n:  1\n",
      "VS rejects N:  5\n",
      "CORRECT VS:  111\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for p in participants:\n",
    "    df_out,notes = process_observer(p)\n",
    "    results[p] = notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'false_alarms_high': 0,\n",
       "  'false_alarms_low': 0,\n",
       "  'tone_detection_accuracy_diff': 0.16666666666666669,\n",
       "  'tone_detection_accuracy_high': 0.25,\n",
       "  'tone_detection_accuracy_low': 0.4166666666666667,\n",
       "  'vs_accuracy_diff': 0.15431235431235435,\n",
       "  'vs_accuracy_high': 0.8153846153846154,\n",
       "  'vs_accuracy_low': 0.9696969696969697},\n",
       " '10': {'false_alarms_high': 0,\n",
       "  'false_alarms_low': 0,\n",
       "  'tone_detection_accuracy_diff': -0.16666666666666663,\n",
       "  'tone_detection_accuracy_high': 0.75,\n",
       "  'tone_detection_accuracy_low': 0.5833333333333334,\n",
       "  'vs_accuracy_diff': 0.12215320910973082,\n",
       "  'vs_accuracy_high': 0.782608695652174,\n",
       "  'vs_accuracy_low': 0.9047619047619048},\n",
       " '2': {'false_alarms_high': 0,\n",
       "  'false_alarms_low': 0,\n",
       "  'tone_detection_accuracy_diff': 0.04166666666666667,\n",
       "  'tone_detection_accuracy_high': 0.08333333333333333,\n",
       "  'tone_detection_accuracy_low': 0.125,\n",
       "  'vs_accuracy_diff': 0.11940298507462688,\n",
       "  'vs_accuracy_high': 0.8059701492537313,\n",
       "  'vs_accuracy_low': 0.9253731343283582},\n",
       " '3': {'false_alarms_high': 0,\n",
       "  'false_alarms_low': 0,\n",
       "  'tone_detection_accuracy_diff': 0.08333333333333326,\n",
       "  'tone_detection_accuracy_high': 0.5833333333333334,\n",
       "  'tone_detection_accuracy_low': 0.6666666666666666,\n",
       "  'vs_accuracy_diff': 0.11268939393939392,\n",
       "  'vs_accuracy_high': 0.78125,\n",
       "  'vs_accuracy_low': 0.8939393939393939},\n",
       " '4': {'false_alarms_high': 0,\n",
       "  'false_alarms_low': 0,\n",
       "  'tone_detection_accuracy_diff': -0.04166666666666663,\n",
       "  'tone_detection_accuracy_high': 0.5416666666666666,\n",
       "  'tone_detection_accuracy_low': 0.5,\n",
       "  'vs_accuracy_diff': -0.01673450927182274,\n",
       "  'vs_accuracy_high': 0.8955223880597015,\n",
       "  'vs_accuracy_low': 0.8787878787878788},\n",
       " '5': {'false_alarms_high': 1,\n",
       "  'false_alarms_low': 0,\n",
       "  'tone_detection_accuracy_diff': 0.0,\n",
       "  'tone_detection_accuracy_high': 0.9166666666666666,\n",
       "  'tone_detection_accuracy_low': 0.9166666666666666,\n",
       "  'vs_accuracy_diff': 0.08390342052313893,\n",
       "  'vs_accuracy_high': 0.8732394366197183,\n",
       "  'vs_accuracy_low': 0.9571428571428572},\n",
       " '6': {'false_alarms_high': 0,\n",
       "  'false_alarms_low': 0,\n",
       "  'tone_detection_accuracy_diff': 0.0,\n",
       "  'tone_detection_accuracy_high': 0.0,\n",
       "  'tone_detection_accuracy_low': 0.0,\n",
       "  'vs_accuracy_diff': 0.019469759734879855,\n",
       "  'vs_accuracy_high': 0.7746478873239436,\n",
       "  'vs_accuracy_low': 0.7941176470588235},\n",
       " '7': {'false_alarms_high': 0,\n",
       "  'false_alarms_low': 0,\n",
       "  'tone_detection_accuracy_diff': 0.04166666666666663,\n",
       "  'tone_detection_accuracy_high': 0.8333333333333334,\n",
       "  'tone_detection_accuracy_low': 0.875,\n",
       "  'vs_accuracy_diff': 0.2229760289461783,\n",
       "  'vs_accuracy_high': 0.7164179104477612,\n",
       "  'vs_accuracy_low': 0.9393939393939394},\n",
       " '8': {'false_alarms_high': 62,\n",
       "  'false_alarms_low': 147,\n",
       "  'tone_detection_accuracy_diff': 0.08333333333333326,\n",
       "  'tone_detection_accuracy_high': 0.8333333333333334,\n",
       "  'tone_detection_accuracy_low': 0.9166666666666666,\n",
       "  'vs_accuracy_diff': 0.1511371973587674,\n",
       "  'vs_accuracy_high': 0.8275862068965517,\n",
       "  'vs_accuracy_low': 0.9787234042553191},\n",
       " '9': {'false_alarms_high': 0,\n",
       "  'false_alarms_low': 0,\n",
       "  'tone_detection_accuracy_diff': 0.04166666666666663,\n",
       "  'tone_detection_accuracy_high': 0.7083333333333334,\n",
       "  'tone_detection_accuracy_low': 0.75,\n",
       "  'vs_accuracy_diff': 0.05464982778415617,\n",
       "  'vs_accuracy_high': 0.7761194029850746,\n",
       "  'vs_accuracy_low': 0.8307692307692308}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing table for visual-search task\n",
    "visual_search_task_data=np.zeros((10,3))\n",
    "\n",
    "for i,p in enumerate(participants):\n",
    "    visual_search_task_data[i,0] = results[p]['vs_accuracy_high']*100\n",
    "    visual_search_task_data[i,1] = results[p]['vs_accuracy_low']*100\n",
    "    visual_search_task_data[i,2] = results[p]['vs_accuracy_diff']*100\n",
    "\n",
    "    \n",
    "visual_search_task_data = np.round(visual_search_task_data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing table for tone-detection task\n",
    "detection_task_data=np.zeros((10,3))\n",
    "\n",
    "for i,p in enumerate(participants):\n",
    "    detection_task_data[i,0] = results[p]['tone_detection_accuracy_high']*100\n",
    "    detection_task_data[i,1] = results[p]['tone_detection_accuracy_low']*100\n",
    "    detection_task_data[i,2] = results[p]['tone_detection_accuracy_diff']*100\n",
    "\n",
    "    \n",
    "detection_task_data = np.round(detection_task_data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing table for false alarms\n",
    "false_alarms_data=np.zeros((10,2))\n",
    "\n",
    "for i,p in enumerate(participants):\n",
    "    false_alarms_data[i,0] = int(results[p]['false_alarms_low'])\n",
    "    false_alarms_data[i,1] = results[p]['false_alarms_high']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('reports/my_table_3.html','wb')\n",
    "f.write('<html><body>')\n",
    "f.write(\"<link rel='stylesheet' type='text/css' href='main.css'>\")\n",
    "#Table for Visual-search task\n",
    "make_table('Visual Search Task: only trials without tones and without false alarms to tones (spacebar responses)',['Participant','Accuracy: high','Accuracy: low','Accuracy: low - high'],participants,visual_search_task_data,f)\n",
    "#Table for Tone-detection task\n",
    "make_table('Tone Detection Task',['Participant','Accuracy: high','Accuracy: low','Accuracy: low - high'],participants,detection_task_data,f)\n",
    "#Table for false alarms (in tone detection)\n",
    "make_table('Tone Detection Task: absolute number of false alarms',['Participant','False alarms: low','False alarms: high'],participants,false_alarms_data,f)\n",
    "f.write('</body></html>')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
