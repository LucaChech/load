{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  exp  participant load  tone_hz  tone_onset  present_absent  \\\n",
      "0      1    3            2  low  No tone      -999.0       No Target   \n",
      "1      2    3            2  low  No tone      -999.0       No Target   \n",
      "2      3    3            2  low  No tone      -999.0  Target Present   \n",
      "3      4    3            2  low  No tone      -999.0       No Target   \n",
      "4      5    3            2  low  No tone      -999.0       No Target   \n",
      "\n",
      "  trial_type  RT_TO    RT_VS  correct_tone  visual_s_acc  \n",
      "0     Normal    NaN      NaN           NaN           NaN  \n",
      "1     Normal    NaN      NaN           NaN           NaN  \n",
      "2     Normal    NaN  1.48111           NaN           1.0  \n",
      "3     Normal    NaN      NaN           NaN           NaN  \n",
      "4     Normal    NaN      NaN           NaN           NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from pdb import set_trace\n",
    "import pdb\n",
    "import scipy\n",
    "#%pdb\n",
    "mypath = 'C:/Users/nilli lab/Desktop/same_format/exp_1/'\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame.from_csv(mypath+'1.csv', header = 0)\n",
    "df1.reset_index(inplace = True)\n",
    "df2 = pd.DataFrame.from_csv(mypath+'2.csv', header = 0)\n",
    "df2.reset_index(inplace = True)\n",
    "df3 = pd.DataFrame.from_csv(mypath+'3.csv', header = 0)\n",
    "df3.reset_index(inplace = True)\n",
    "df4 = pd.DataFrame.from_csv(mypath+'4.csv', header = 0)\n",
    "df4.reset_index(inplace = True)\n",
    "df5 = pd.DataFrame.from_csv(mypath+'5.csv', header = 0)\n",
    "df5.reset_index(inplace = True)\n",
    "df6 = pd.DataFrame.from_csv(mypath+'6.csv', header = 0)\n",
    "df6.reset_index(inplace = True)\n",
    "df7 = pd.DataFrame.from_csv(mypath+'7.csv', header = 0)\n",
    "df7.reset_index(inplace = True)\n",
    "df8 = pd.DataFrame.from_csv(mypath+'8.csv', header = 0)\n",
    "df8.reset_index(inplace = True)\n",
    "df9 = pd.DataFrame.from_csv(mypath+'9.csv', header = 0)\n",
    "df9.reset_index(inplace = True)\n",
    "df10 = pd.DataFrame.from_csv(mypath+'10.csv', header = 0)\n",
    "df10.reset_index(inplace = True)\n",
    "df11 = pd.DataFrame.from_csv(mypath+'11.csv', header = 0)\n",
    "df11.reset_index(inplace = True)\n",
    "df12 = pd.DataFrame.from_csv(mypath+'12.csv', header = 0)\n",
    "df12.reset_index(inplace = True)\n",
    "df13 = pd.DataFrame.from_csv(mypath+'13.csv', header = 0)\n",
    "df13.reset_index(inplace = True)\n",
    "df14 = pd.DataFrame.from_csv(mypath+'14.csv', header = 0)\n",
    "df14.reset_index(inplace = True)\n",
    "df15 = pd.DataFrame.from_csv(mypath+'15.csv', header = 0)\n",
    "df15.reset_index(inplace = True)\n",
    "df16 = pd.DataFrame.from_csv(mypath+'16.csv', header = 0)\n",
    "df16.reset_index(inplace = True)\n",
    "\n",
    "frames = [df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16]\n",
    "df = pd.concat(frames)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_ordered = df[['index','exp','participant','Load','tone_Hz','tone_onset','present_absent','trial_type','RT_TO','RT_VS','correct_tone','visual_s_acc']]\n",
    "cols =         ['index','exp','participant','load','tone_hz','tone_onset','present_absent','trial_type','RT_TO','RT_VS','correct_tone','visual_s_acc']\n",
    "df_ordered.columns = cols\n",
    "df_ordered.to_csv('C:/Users/nilli lab/Desktop/same_format/exp1.csv')\n",
    "\n",
    "\n",
    "\n",
    "mypath = 'C:/Users/nilli lab/Desktop/same_format/exp_2/'\n",
    "\n",
    "df1 = pd.DataFrame.from_csv(mypath+'1.csv', header = 0)\n",
    "df1.reset_index(inplace = True)\n",
    "df2 = pd.DataFrame.from_csv(mypath+'2.csv', header = 0)\n",
    "df2.reset_index(inplace = True)\n",
    "df3 = pd.DataFrame.from_csv(mypath+'3.csv', header = 0)\n",
    "df3.reset_index(inplace = True)\n",
    "df4 = pd.DataFrame.from_csv(mypath+'4.csv', header = 0)\n",
    "df4.reset_index(inplace = True)\n",
    "df5 = pd.DataFrame.from_csv(mypath+'5.csv', header = 0)\n",
    "df5.reset_index(inplace = True)\n",
    "df7 = pd.DataFrame.from_csv(mypath+'7.csv', header = 0)\n",
    "df7.reset_index(inplace = True)\n",
    "df8 = pd.DataFrame.from_csv(mypath+'8.csv', header = 0)\n",
    "df8.reset_index(inplace = True)\n",
    "df9 = pd.DataFrame.from_csv(mypath+'9.csv', header = 0)\n",
    "df9.reset_index(inplace = True)\n",
    "df10 = pd.DataFrame.from_csv(mypath+'10.csv', header = 0)\n",
    "df10.reset_index(inplace = True)\n",
    "df11 = pd.DataFrame.from_csv(mypath+'11.csv', header = 0)\n",
    "df11.reset_index(inplace = True)\n",
    "df12 = pd.DataFrame.from_csv(mypath+'12.csv', header = 0)\n",
    "df12.reset_index(inplace = True)\n",
    "df14 = pd.DataFrame.from_csv(mypath+'14.csv', header = 0)\n",
    "df14.reset_index(inplace = True)\n",
    "df15 = pd.DataFrame.from_csv(mypath+'15.csv', header = 0)\n",
    "df15.reset_index(inplace = True)\n",
    "df17 = pd.DataFrame.from_csv(mypath+'17.csv', header = 0)\n",
    "df17.reset_index(inplace = True)\n",
    "\n",
    "frames = [df1,df2,df3,df4,df5,df7,df8,df9,df10,df11,df12,df14,df15,df17]\n",
    "df = pd.concat(frames)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.to_csv('C:/Users/nilli lab/Desktop/same_format/exp2.csv')\n",
    "\n",
    "mypath = 'C:/Users/nilli lab/Desktop/same_format/exp_3/'\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame.from_csv(mypath+'2.csv', header = 0)\n",
    "df2.reset_index(inplace = True)\n",
    "df3 = pd.DataFrame.from_csv(mypath+'3.csv', header = 0)\n",
    "df3.reset_index(inplace = True)\n",
    "df4 = pd.DataFrame.from_csv(mypath+'4.csv', header = 0)\n",
    "df4.reset_index(inplace = True)\n",
    "df5 = pd.DataFrame.from_csv(mypath+'5.csv', header = 0)\n",
    "df5.reset_index(inplace = True)\n",
    "df6 = pd.DataFrame.from_csv(mypath+'6.csv', header = 0)\n",
    "df6.reset_index(inplace = True)\n",
    "df7 = pd.DataFrame.from_csv(mypath+'7.csv', header = 0)\n",
    "df7.reset_index(inplace = True)\n",
    "\n",
    "frames = [df2,df3,df4,df5,df6,df7]\n",
    "df = pd.concat(frames)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df= df[['index','exp','participant','load','tone_hz','tone_onset','present_absent','trial_type','RT_TO','RT_VS','correct_dt','visual_s_acc']]\n",
    "cols =         ['index','exp','participant','load','tone_hz','tone_onset','present_absent','trial_type','RT_TO','RT_VS','correct_tone','visual_s_acc']\n",
    "df.columns = cols\n",
    "df.to_csv('C:/Users/nilli lab/Desktop/same_format/exp3.csv')\n",
    "print df.head()\n",
    "mypath = 'C:/Users/nilli lab/Desktop/same_format/'\n",
    "exp1 = pd.DataFrame.from_csv(mypath+'exp1.csv', header = 0)\n",
    "exp2 = pd.DataFrame.from_csv(mypath+'exp2.csv', header = 0)\n",
    "exp3 = pd.DataFrame.from_csv(mypath+'exp3.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [exp1,exp2,exp3]\n",
    "df = pd.concat(frames)\n",
    "df.reset_index(drop=False, inplace=True)\n",
    "df.drop('level_0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    if df.loc[i,'tone_onset'] == -999:\n",
    "        df.loc[i,'tone_onset'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['onset_2l'] = None\n",
    "for i in range(df.shape[0]):\n",
    "    if (pd.notnull(df.loc[i,'tone_onset'])) and(0  < df.loc[i,'tone_onset'] <= 500):\n",
    "        df.loc[i,'onset_2l'] = 1\n",
    "    elif (pd.notnull(df.loc[i,'tone_onset'])) and(500  < df.loc[i,'tone_onset'] <= 1000):\n",
    "        df.loc[i,'onset_2l'] = 2\n",
    "df['onset_4l'] = None\n",
    "for i in range(df.shape[0]):\n",
    "    if (pd.notnull(df.loc[i,'tone_onset'])) and(0  < df.loc[i,'tone_onset'] <= 250):\n",
    "        df.loc[i,'onset_4l'] = 1\n",
    "    elif (pd.notnull(df.loc[i,'tone_onset'])) and(250  < df.loc[i,'tone_onset'] <= 500):\n",
    "        df.loc[i,'onset_4l'] = 2\n",
    "    elif (pd.notnull(df.loc[i,'tone_onset'])) and(500  < df.loc[i,'tone_onset'] <= 750):\n",
    "        df.loc[i,'onset_4l'] = 3\n",
    "    elif (pd.notnull(df.loc[i,'tone_onset'])) and(750  < df.loc[i,'tone_onset'] <= 1000):\n",
    "        df.loc[i,'onset_4l'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/nilli lab/Desktop/same_format/all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['trial_type'] == 'Critical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/nilli lab/Desktop/same_format/all_critical.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(mypath+'all_critical_f.csv', header = 0)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('level_0',axis=1,inplace=True)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials with both tone and probe are excluded (regardless of visual search accuracy)\n",
    "df['correct_tone_no_probe'] = df['correct_tone']\n",
    "for i in range(1,df.shape[0]):\n",
    "    if df.loc[i,'correct_tone'] == 1 :\n",
    "        if pd.notnull(df.loc[i,'visual_s_acc']):\n",
    "            df.loc[i,'correct_tone_no_probe'] = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials with both tone and probe are excluded where the response to the visual search was incorrect are excluded\n",
    "df['correct_tone_if'] = df['correct_tone']\n",
    "for i in range(1,df.shape[0]):\n",
    "    if df.loc[i,'correct_tone'] == 1 and pd.notnull(df.loc[i,'visual_s_acc']):\n",
    "        if df.loc[i,'visual_s_acc'] == 0:\n",
    "            df.loc[i,'correct_tone_if'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(p):\n",
    "    global accuracy_list\n",
    "    df_p = df[df['participant']==p]\n",
    "    df_p.reset_index(inplace=True)\n",
    "\n",
    "    low_1_n_no_p = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==1)])\n",
    "    low_1_c_no_p = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==1) & (df_p['correct_tone_no_probe']==1)])\n",
    "    \n",
    "    low_2_n_no_p = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==2)])\n",
    "    low_2_c_no_p = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==2) & (df_p['correct_tone_no_probe']==1)])\n",
    "    \n",
    "    low_3_n_no_p = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==3)])\n",
    "    low_3_c_no_p = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==3) & (df_p['correct_tone_no_probe']==1)])\n",
    "    \n",
    "    low_4_n_no_p = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==4)])\n",
    "    low_4_c_no_p = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==4) & (df_p['correct_tone_no_probe']==1)])\n",
    "    \n",
    "    high_1_n_no_p = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==1)])\n",
    "    high_1_c_no_p = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==1) & (df_p['correct_tone_no_probe']==1)])\n",
    "    \n",
    "    high_2_n_no_p = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==2)])\n",
    "    high_2_c_no_p = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==2) & (df_p['correct_tone_no_probe']==1)])\n",
    "    \n",
    "    high_3_n_no_p = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==3)])\n",
    "    high_3_c_no_p = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==3) & (df_p['correct_tone_no_probe']==1)])\n",
    "    \n",
    "    high_4_n_no_p = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==4)])\n",
    "    high_4_c_no_p = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==4) & (df_p['correct_tone_no_probe']==1)])\n",
    "    \n",
    "    \n",
    "    low_1_acc_np = round(low_1_c_no_p/low_1_n_no_p*100,2)\n",
    "    low_2_acc_np = round(low_2_c_no_p/low_2_n_no_p*100,2)\n",
    "    low_3_acc_np = round(low_3_c_no_p/low_3_n_no_p*100,2)\n",
    "    low_4_acc_np = round(low_4_c_no_p/low_4_n_no_p*100,2)\n",
    "    high_1_acc_np = round(high_1_c_no_p/high_1_n_no_p*100,2)\n",
    "    high_2_acc_np = round(high_2_c_no_p/high_2_n_no_p*100,2)\n",
    "    high_3_acc_np = round(high_3_c_no_p/high_3_n_no_p*100,2)\n",
    "    high_4_acc_np = round(high_4_c_no_p/high_4_n_no_p*100,2)\n",
    "    \n",
    "    low_acc_np = round((low_1_c_no_p+low_2_c_no_p+low_3_c_no_p+low_4_c_no_p)/(low_1_n_no_p+low_2_n_no_p+low_3_n_no_p+low_4_n_no_p)*100,2)\n",
    "    high_acc_np = round((high_1_c_no_p+high_2_c_no_p+high_3_c_no_p+high_4_c_no_p)/(high_1_n_no_p+high_2_n_no_p+high_3_n_no_p+high_4_n_no_p)*100,2)\n",
    "    onset_1_np = round((low_1_c_no_p+high_1_c_no_p)/(low_1_n_no_p+high_1_n_no_p)*100,2)\n",
    "    onset_2_np = round((low_2_c_no_p+high_2_c_no_p)/(low_2_n_no_p+high_2_n_no_p)*100,2)\n",
    "    onset_3_np = round((low_3_c_no_p+high_3_c_no_p)/(low_3_n_no_p+high_3_n_no_p)*100,2)\n",
    "    onset_4_np = round((low_4_c_no_p+high_4_c_no_p)/(low_4_n_no_p+high_4_n_no_p)*100,2)\n",
    "    ################################################################################################\n",
    "    low_1_n = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==1)])\n",
    "    low_1_c = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==1) & (df_p['correct_tone']==1)])\n",
    "    \n",
    "    low_2_n = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==2)])\n",
    "    low_2_c = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==2) & (df_p['correct_tone']==1)])\n",
    "    \n",
    "    low_3_n = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==3)])\n",
    "    low_3_c = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==3) & (df_p['correct_tone']==1)])\n",
    "    \n",
    "    low_4_n = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==4)])\n",
    "    low_4_c = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==4) & (df_p['correct_tone']==1)])\n",
    "    \n",
    "    high_1_n = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==1)])\n",
    "    high_1_c = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==1) & (df_p['correct_tone']==1)])\n",
    "    \n",
    "    high_2_n = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==2)])\n",
    "    high_2_c = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==2) & (df_p['correct_tone']==1)])\n",
    "    \n",
    "    high_3_n = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==3)])\n",
    "    high_3_c = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==3) & (df_p['correct_tone']==1)])\n",
    "    \n",
    "    high_4_n = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==4)])\n",
    "    high_4_c = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==4) & (df_p['correct_tone']==1)])\n",
    "    \n",
    "    \n",
    "    low_1_acc = round(low_1_c/low_1_n*100,2)\n",
    "    low_2_acc = round(low_2_c/low_2_n*100,2)\n",
    "    low_3_acc = round(low_3_c/low_3_n*100,2)\n",
    "    low_4_acc = round(low_4_c/low_4_n*100,2)\n",
    "    high_1_acc = round(high_1_c/high_1_n*100,2)\n",
    "    high_2_acc = round(high_2_c/high_2_n*100,2)\n",
    "    high_3_acc = round(high_3_c/high_3_n*100,2)\n",
    "    high_4_acc = round(high_4_c/high_4_n*100,2)\n",
    "    \n",
    "    low_acc = round((low_1_c+low_2_c+low_3_c+low_4_c)/(low_1_n+low_2_n+low_3_n+low_4_n)*100,2)\n",
    "    high_acc = round((high_1_c+high_2_c+high_3_c+high_4_c)/(high_1_n+high_2_n+high_3_n+high_4_n)*100,2)\n",
    "    onset_1 = round((low_1_c+high_1_c)/(low_1_n+high_1_n)*100,2)\n",
    "    onset_2 = round((low_2_c+high_2_c)/(low_2_n+high_2_n)*100,2)\n",
    "    onset_3 = round((low_3_c+high_3_c)/(low_3_n+high_3_n)*100,2)\n",
    "    onset_4 = round((low_4_c+high_4_c)/(low_4_n+high_4_n)*100,2)\n",
    "    ################################################################################################\n",
    "    low_1_n_if = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==1)])\n",
    "    low_1_c_if = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==1) & (df_p['correct_tone_if']==1)])\n",
    "    \n",
    "    low_2_n_if = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==2)])\n",
    "    low_2_c_if = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==2) & (df_p['correct_tone_if']==1)])\n",
    "    \n",
    "    low_3_n_if = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==3)])\n",
    "    low_3_c_if = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==3) & (df_p['correct_tone_if']==1)])\n",
    "    \n",
    "    low_4_n_if = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==4)])\n",
    "    low_4_c_if = len(df_p[(df_p['load']=='low') & (df_p['onset_4l']==4) & (df_p['correct_tone_if']==1)])\n",
    "    \n",
    "    high_1_n_if = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==1)])\n",
    "    high_1_c_if = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==1) & (df_p['correct_tone_if']==1)])\n",
    "    \n",
    "    high_2_n_if = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==2)])\n",
    "    high_2_c_if = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==2) & (df_p['correct_tone_if']==1)])\n",
    "    \n",
    "    high_3_n_if = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==3)])\n",
    "    high_3_c_if = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==3) & (df_p['correct_tone_if']==1)])\n",
    "    \n",
    "    high_4_n_if = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==4)])\n",
    "    high_4_c_if = len(df_p[(df_p['load']=='high') & (df_p['onset_4l']==4) & (df_p['correct_tone_if']==1)])\n",
    "    \n",
    "    \n",
    "    low_1_acc_if = round(low_1_c_if/low_1_n_if*100,2)\n",
    "    low_2_acc_if = round(low_2_c_if/low_2_n_if*100,2)\n",
    "    low_3_acc_if = round(low_3_c_if/low_3_n_if*100,2)\n",
    "    low_4_acc_if = round(low_4_c_if/low_4_n_if*100,2)\n",
    "    high_1_acc_if = round(high_1_c_if/high_1_n_if*100,2)\n",
    "    high_2_acc_if = round(high_2_c_if/high_2_n_if*100,2)\n",
    "    high_3_acc_if = round(high_3_c_if/high_3_n_if*100,2)\n",
    "    high_4_acc_if = round(high_4_c_if/high_4_n_if*100,2)\n",
    "    \n",
    "    low_acc_if = round((low_1_c_if+low_2_c_if+low_3_c_if+low_4_c_if)/(low_1_n_if+low_2_n_if+low_3_n_if+low_4_n_if)*100,2)\n",
    "    high_acc_if = round((high_1_c_if+high_2_c_if+high_3_c_if+high_4_c_if)/(high_1_n_if+high_2_n_if+high_3_n_if+high_4_n_if)*100,2)\n",
    "    onset_1_if = round((low_1_c_if+high_1_c_if)/(low_1_n_if+high_1_n_if)*100,2)\n",
    "    onset_2_if = round((low_2_c_if+high_2_c_if)/(low_2_n_if+high_2_n_if)*100,2)\n",
    "    onset_3_if = round((low_3_c_if+high_3_c_if)/(low_3_n_if+high_3_n_if)*100,2)\n",
    "    onset_4_if = round((low_4_c_if+high_4_c_if)/(low_4_n_if+high_4_n_if)*100,2)\n",
    "    \n",
    "    \n",
    "    a = 1\n",
    "    if p <= 16:\n",
    "        a = a\n",
    "    #elif 17 <= p <= 30:\n",
    "    #    a = 2\n",
    "    else:\n",
    "        a = 2\n",
    "    accuracy = [a,low_1_acc_if,low_2_acc_if,low_3_acc_if,low_4_acc_if,high_1_acc_if,high_2_acc_if,high_3_acc_if,high_4_acc_if]\n",
    "    #accuracy = [a,low_1_acc,low_2_acc,low_3_acc,low_4_acc,high_1_acc,high_2_acc,high_3_acc,high_4_acc,\n",
    "               #low_1_acc_np,low_2_acc_np,low_3_acc_np,low_4_acc_np,high_1_acc_np,high_2_acc_np,high_3_acc_np,high_4_acc_np,\n",
    "               #low_1_acc_if,low_2_acc_if,low_3_acc_if,low_4_acc_if,high_1_acc_if,high_2_acc_if,high_3_acc_if,high_4_acc_if]\n",
    "    accuracy_list.append(accuracy)\n",
    "    # line below is for using the function in a loop in range(number of participants)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_header = ['experiment','low','high','onset_1','onset_2','onset_3','onset_4','low_1_acc','low_2_acc','low_3_acc','low_4_acc','high_1_acc','high_2_acc','high_3_acc','high_4_acc']\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,36):\n",
    "    get_accuracy(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"C:/Users/nilli lab/Desktop/same_format/output.csv\", \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_accuracy(p):\n",
    "    df_p = df[df['participant']==p]\n",
    "    df_p.reset_index(inplace=True)\n",
    "\n",
    "    low_1_n = 0\n",
    "    low_2_n = 0\n",
    "    low_3_n = 0\n",
    "    low_4_n = 0\n",
    "    high_1_n = 0\n",
    "    high_2_n = 0\n",
    "    high_3_n = 0\n",
    "    high_4_n = 0\n",
    "    low_1_c = 0\n",
    "    low_2_c = 0\n",
    "    low_3_c = 0\n",
    "    low_4_c = 0\n",
    "    high_1_c = 0\n",
    "    high_2_c = 0\n",
    "    high_3_c = 0\n",
    "    high_4_c = 0\n",
    "    low_1_acc = 0\n",
    "    low_2_acc = 0\n",
    "    low_3_acc = 0\n",
    "    low_4_acc = 0\n",
    "    high_1_acc = 0\n",
    "    high_2_acc = 0\n",
    "    high_3_acc = 0\n",
    "    high_4_acc = 0\n",
    "\n",
    "\n",
    "    for i in range(df_p.shape[0]):\n",
    "        if df_p.loc[i,'load'] == 'low' and df_p.loc[i,'onset_4l'] == 1:\n",
    "            low_1_n = low_1_n + 1\n",
    "            if df_p.loc[i,'correct_tone'] == 1:\n",
    "                low_1_c = low_1_c + 1\n",
    "        elif df_p.loc[i,'load'] == 'low' and df_p.loc[i,'onset_4l'] == 2:\n",
    "            low_2_n = low_2_n + 1\n",
    "            if df_p.loc[i,'correct_tone'] == 1:\n",
    "                low_2_c = low_2_c + 1\n",
    "        elif df_p.loc[i,'load'] == 'low' and df_p.loc[i,'onset_4l'] == 3:\n",
    "            low_3_n = low_3_n + 1\n",
    "            if df_p.loc[i,'correct_tone'] == 1:\n",
    "                low_3_c = low_3_c + 1\n",
    "        elif df_p.loc[i,'load'] == 'low' and df_p.loc[i,'onset_4l'] == 4:\n",
    "            low_4_n = low_4_n + 1\n",
    "            if df_p.loc[i,'correct_tone'] == 1:\n",
    "                low_4_c = low_1_c + 1\n",
    "        elif df_p.loc[i,'load'] == 'high' and df_p.loc[i,'onset_4l'] == 1:\n",
    "            high_1_n = high_1_n + 1\n",
    "            if df_p.loc[i,'correct_tone'] == 1:\n",
    "                high_1_c = high_1_c + 1\n",
    "        elif df_p.loc[i,'load'] == 'high' and df_p.loc[i,'onset_4l'] == 2:\n",
    "            high_2_n = high_2_n + 1\n",
    "            if df_p.loc[i,'correct_tone'] == 1:\n",
    "                high_2_c = high_2_c + 1\n",
    "        elif df_p.loc[i,'load'] == 'high' and df_p.loc[i,'onset_4l'] == 3:\n",
    "            high_3_n = high_3_n + 1\n",
    "            if df_p.loc[i,'correct_tone'] == 1:\n",
    "                high_3_c = high_3_c + 1\n",
    "        elif df_p.loc[i,'load'] == 'high' and df_p.loc[i,'onset_4l'] == 4:\n",
    "            high_4_n = high_4_n + 1\n",
    "            if df_p.loc[i,'correct_tone'] == 1:\n",
    "                high_4_c = high_4_c + 1\n",
    "        #print i, low_4_n, low_4_c\n",
    "\n",
    "    low_1_acc = low_1_c/low_1_n\n",
    "    low_2_acc = low_2_c/low_2_n\n",
    "    low_3_acc = low_3_c/low_3_n\n",
    "    low_4_acc = low_4_c/low_4_n\n",
    "    high_1_acc = high_1_c/high_1_n\n",
    "    high_2_acc = high_2_c/high_2_n\n",
    "    high_3_acc = high_3_c/high_3_n\n",
    "    high_4_acc = high_4_c/high_4_n\n",
    "    \n",
    "    a = df_p[(df_p['load']=='low') & (df_p['onset_4l']==4)]\n",
    "    b = df_p[(df_p['load']=='low') & (df_p['onset_4l']==4) & (df_p['correct_tone']==1)]\n",
    "    print len(a)\n",
    "    print len(b)\n",
    "    accuracy = [low_1_acc,low_2_acc,low_3_acc,low_4_acc,high_1_acc,high_2_acc,high_3_acc,high_4_acc]\n",
    "    #print low_4_c\n",
    "    #print low_4_n\n",
    "    return accuracy\n",
    "\n",
    "load = df.groupby(['participant','load','correct_tone'])['correct_tone'].count()\n",
    "load.to_csv('C:/Users/nilli lab/Desktop/same_format/load.csv')\n",
    "onset_2 = df.groupby(['participant','load','onset_2l','correct_tone'])['correct_tone'].count()\n",
    "onset_2.to_csv('C:/Users/nilli lab/Desktop/same_format/load.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
